{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting transformers==4.41.0\n",
      "  Using cached transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from transformers==4.41.0) (3.19.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers==4.41.0)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from transformers==4.41.0) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from transformers==4.41.0) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.41.0)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.41.0)\n",
      "  Using cached regex-2025.11.3-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers==4.41.0)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.0)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.41.0)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.41.0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from tqdm>=4.27->transformers==4.41.0) (0.4.6)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.41.0)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.41.0)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.41.0)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.41.0)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 25.1 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "Using cached regex-2025.11.3-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------- -----------------------------  3/12 [regex]\n",
      "   ----------------------- ----------------  7/12 [certifi]\n",
      "   ------------------------------ ---------  9/12 [huggingface-hub]\n",
      "   --------------------------------- ------ 10/12 [tokenizers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [transformers]\n",
      "   ---------------------------------------- 12/12 [transformers]\n",
      "\n",
      "Successfully installed certifi-2025.11.12 charset_normalizer-3.4.4 huggingface-hub-0.36.0 idna-3.11 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 tokenizers-0.19.1 tqdm-4.67.1 transformers-4.41.0 urllib3-2.5.0\n",
      "Requirement already satisfied: biopython in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (1.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from biopython) (2.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 8.9/11.3 MB 46.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 35.5 MB/s  0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (2.1.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\user\\anaconda3\\envs\\glm\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 8.1/8.9 MB 41.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 36.9 MB/s  0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 7.3/41.3 MB 34.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 15.2/41.3 MB 36.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 22.5/41.3 MB 36.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 30.1/41.3 MB 36.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.3 MB 35.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.2/41.3 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 31.6 MB/s  0:00:01\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers==4.41.0\n",
    "!pip install biopython\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "Device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• GPU: NVIDIA GeForce RTX 4060\n",
      "\n",
      "üìå Ïô∏Î∂ÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú (GRCh38 + CHM13)\n",
      "üëâ Ï†ÑÏ≤¥ Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞ Í∞úÏàò: 9502199\n",
      "üîª ÏÉòÌîåÎßÅ: 120000\n",
      "\n",
      "üìå InfoNCE pair ÏÉùÏÑ±\n",
      "üëâ test ÏãúÌÄÄÏä§ Í∞úÏàò: 13711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\glm\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--InstaDeepAI--nucleotide-transformer-v2-500m-multi-species. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "A new version of the following files was downloaded from https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-500m-multi-species:\n",
      "- esm_config.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-500m-multi-species:\n",
      "- modeling_esm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_18796\\2743362785.py:189: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_FP16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ InfoNCE ÌïôÏäµ ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1:   0%|          | 0/938 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_18796\\2743362785.py:211: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_FP16):\n",
      "EPOCH 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [05:44<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 1 Loss = 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [05:53<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 2 Loss = 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [06:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 3 Loss = 0.0050\n",
      "\n",
      "üîç test ÏûÑÎ≤†Îî© ÏÉùÏÑ±\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 429/429 [13:27<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Í≤∞Í≥º Ï†ÄÏû•\n",
      "üéâ ÏôÑÎ£å! ÌååÏùº Ï†ÄÏû•Îê® ‚Üí C:\\Users\\USER\\Desktop\\Ï†ÑÏßÄÏòà\\submission_infonce_v4.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 0) Í≤ΩÎ°ú ÏÑ§Ï†ï (üî• ÏßÄÏòàÎãò PC Í∏∞Ï§Ä)\n",
    "# =====================================================\n",
    "BASE = r\"C:\\Users\\USER\\Desktop\\Ï†ÑÏßÄÏòà\"\n",
    "\n",
    "GRCH38_CSV = os.path.join(BASE, \"grch38_windows_seq.csv\")\n",
    "CHM13_CSV  = os.path.join(BASE, \"chm13_windows_seq.csv\")\n",
    "\n",
    "TEST_PATH        = os.path.join(BASE, \"test.csv\")\n",
    "SAMPLE_SUB_PATH  = os.path.join(BASE, \"sample_submission.csv\")\n",
    "OUT_PATH         = os.path.join(BASE, \"submission_infonce_v4.csv\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1) InfoNCE ÌïôÏäµ ÏÑ§Ï†ï\n",
    "# =====================================================\n",
    "SEED = 42\n",
    "MODEL_ID = \"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\"\n",
    "\n",
    "MAX_EXT_SEQ = 120000     # Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞ ÏÉòÌîåÎßÅ ÏµúÎåÄ Í∞úÏàò\n",
    "NUM_PAIRS   = 30000      # InfoNCE pair Í∞úÏàò\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "LAST_N_LAYERS = 4\n",
    "OUTPUT_DIM = 512\n",
    "\n",
    "TRAIN_EPOCHS = 3\n",
    "BATCH_SIZE_TR = 32\n",
    "BATCH_SIZE_INFER = 32\n",
    "\n",
    "LR_HEAD = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TEMPERATURE = 0.07\n",
    "USE_FP16 = True\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2) Utility\n",
    "# =====================================================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def l2_normalize(x, eps=1e-12):\n",
    "    return x / x.norm(p=2, dim=-1, keepdim=True).clamp(min=eps)\n",
    "\n",
    "\n",
    "_rc_map = str.maketrans(\"ACGT\", \"TGCA\")\n",
    "def reverse_complement(seq):\n",
    "    return seq.translate(_rc_map)[::-1]\n",
    "\n",
    "\n",
    "def apply_snv(seq, k=1):\n",
    "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    s = list(seq)\n",
    "    idxs = random.sample(range(len(s)), k)\n",
    "    for idx in idxs:\n",
    "        orig = s[idx]\n",
    "        s[idx] = random.choice([b for b in bases if b != orig])\n",
    "    return \"\".join(s)\n",
    "\n",
    "\n",
    "def generate_pairs(seqs: List[str], num_pairs: int):\n",
    "    pairs = []\n",
    "    for _ in range(num_pairs):\n",
    "        anchor = random.choice(seqs)\n",
    "\n",
    "        # Í∏∏Î©¥ MAX_LENGTHÎ°ú ÎûúÎç§ Ïä¨ÎùºÏù¥Ïä§\n",
    "        if len(anchor) > MAX_LENGTH:\n",
    "            st = random.randint(0, len(anchor) - MAX_LENGTH)\n",
    "            anchor = anchor[st:st + MAX_LENGTH]\n",
    "\n",
    "        r = random.random()\n",
    "        if r < 0.4:\n",
    "            pos = anchor\n",
    "        elif r < 0.8:\n",
    "            pos = apply_snv(anchor, random.randint(1, 2))\n",
    "        else:\n",
    "            pos = reverse_complement(apply_snv(anchor))\n",
    "\n",
    "        pairs.append([anchor, pos])\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3) RobustModel\n",
    "# =====================================================\n",
    "class RobustModel(nn.Module):\n",
    "    def __init__(self, hidden, last_n, out_dim):\n",
    "        super().__init__()\n",
    "        self.last_n = last_n\n",
    "        self.layer_weights = nn.Parameter(torch.zeros(last_n))\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(hidden, hidden * 2),\n",
    "            nn.LayerNorm(hidden * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden * 2, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states, mask):\n",
    "        stack = torch.stack(hidden_states[-self.last_n:], 0)\n",
    "        w = F.softmax(self.layer_weights, dim=0).view(-1, 1, 1, 1)\n",
    "\n",
    "        feat = (stack * w).sum(0)\n",
    "        mask = mask.unsqueeze(-1).float()\n",
    "\n",
    "        summed = (feat * mask).sum(1)\n",
    "        denom = mask.sum(1).clamp(min=1e-9)\n",
    "\n",
    "        mean_emb = summed / denom\n",
    "        return l2_normalize(self.proj(mean_emb))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4) Main\n",
    "# =====================================================\n",
    "def main():\n",
    "\n",
    "    print(\"üî• GPU:\", torch.cuda.get_device_name(0))\n",
    "    set_seed(SEED)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) Ïù¥ÎØ∏ Ï†ÑÏ≤òÎ¶¨Îêú CSV Î∂àÎü¨Ïò§Í∏∞ (GRCh38 + CHM13)\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\nüìå Ïô∏Î∂ÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú (GRCh38 + CHM13)\")\n",
    "    df1 = pd.read_csv(GRCH38_CSV)\n",
    "    df2 = pd.read_csv(CHM13_CSV)\n",
    "\n",
    "    combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(\"üëâ Ï†ÑÏ≤¥ Ïô∏Î∂Ä Îç∞Ïù¥ÌÑ∞ Í∞úÏàò:\", len(combined))\n",
    "\n",
    "    ext_sequences = combined[\"seq\"].astype(str).tolist()\n",
    "\n",
    "    # ÏÉòÌîåÎßÅ\n",
    "    if len(ext_sequences) > MAX_EXT_SEQ:\n",
    "        idx = np.random.choice(len(ext_sequences), MAX_EXT_SEQ, replace=False)\n",
    "        ext_sequences = [ext_sequences[i] for i in idx]\n",
    "        print(\"üîª ÏÉòÌîåÎßÅ:\", len(ext_sequences))\n",
    "\n",
    "    # InfoNCE Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "    print(\"\\nüìå InfoNCE pair ÏÉùÏÑ±\")\n",
    "    pair_data = generate_pairs(ext_sequences, NUM_PAIRS)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) test.csv Î°úÎìú\n",
    "    # -------------------------------------------------\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    test_sequences = test_df[\"seq\"].astype(str).tolist()\n",
    "    print(\"üëâ test ÏãúÌÄÄÏä§ Í∞úÏàò:\", len(test_sequences))\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) Î∞±Î≥∏ Î™®Îç∏ Î°úÎìú\n",
    "    # -------------------------------------------------\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    backbone = AutoModelForMaskedLM.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    backbone = backbone.to(device).eval()\n",
    "\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4) Ìó§Îìú Î™®Îç∏\n",
    "    # -------------------------------------------------\n",
    "    model = RobustModel(backbone.config.hidden_size, LAST_N_LAYERS, OUTPUT_DIM).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_FP16)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 5) InfoNCE ÌïôÏäµ\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\nüöÄ InfoNCE ÌïôÏäµ ÏãúÏûë\")\n",
    "\n",
    "    for epoch in range(TRAIN_EPOCHS):\n",
    "        random.shuffle(pair_data)\n",
    "        epoch_losses = []\n",
    "\n",
    "        for i in tqdm(range(0, len(pair_data), BATCH_SIZE_TR), desc=f\"EPOCH {epoch+1}\"):\n",
    "            batch = pair_data[i:i+BATCH_SIZE_TR]\n",
    "            anchors, positives = zip(*batch)\n",
    "\n",
    "            seqs = list(anchors) + list(positives)\n",
    "\n",
    "            enc = tokenizer(\n",
    "                seqs, padding=True, truncation=True,\n",
    "                max_length=MAX_LENGTH, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=USE_FP16):\n",
    "                with torch.no_grad():\n",
    "                    out = backbone(**enc, output_hidden_states=True)\n",
    "\n",
    "                emb = model(out.hidden_states, enc[\"attention_mask\"])\n",
    "                B = len(batch)\n",
    "\n",
    "                ea, ep = emb[:B], emb[B:]\n",
    "                sim = (ea @ ep.T) / TEMPERATURE\n",
    "                labels = torch.arange(B, device=device)\n",
    "\n",
    "                loss = (F.cross_entropy(sim, labels) +\n",
    "                        F.cross_entropy(sim.T, labels)) / 2\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        print(f\"üìâ Epoch {epoch+1} Loss = {np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 6) Ï∂îÎ°†\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\nüîç test ÏûÑÎ≤†Îî© ÏÉùÏÑ±\")\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(test_sequences), BATCH_SIZE_INFER)):\n",
    "        batch = test_sequences[i:i+BATCH_SIZE_INFER]\n",
    "\n",
    "        view1 = batch\n",
    "        view2 = [reverse_complement(x) for x in batch]\n",
    "\n",
    "        seqs = view1 + view2\n",
    "\n",
    "        enc = tokenizer(\n",
    "            seqs, padding=True, truncation=True,\n",
    "            max_length=MAX_LENGTH, return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = backbone(**enc, output_hidden_states=True)\n",
    "            emb_all = model(out.hidden_states, enc[\"attention_mask\"])\n",
    "\n",
    "            B = len(batch)\n",
    "            emb_mean = (emb_all[:B] + emb_all[B:]) / 2.0\n",
    "            outputs.append(emb_mean.cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(outputs, axis=0)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 7) Ï†ÄÏû•\n",
    "    # -------------------------------------------------\n",
    "    print(\"\\nüíæ Í≤∞Í≥º Ï†ÄÏû•\")\n",
    "\n",
    "    col_names = [f\"emb_{i:04d}\" for i in range(OUTPUT_DIM)]\n",
    "    df_emb = pd.DataFrame(embeddings, columns=col_names)\n",
    "\n",
    "    final = pd.concat([test_df[[\"ID\"]], df_emb], axis=1)\n",
    "    final.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "    print(\"üéâ ÏôÑÎ£å! ÌååÏùº Ï†ÄÏû•Îê® ‚Üí\", OUT_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
